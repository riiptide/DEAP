{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ashishshaji/EEG_Classification_Deeplearning/blob/master/Deapdataset_emotion/Deap_Valance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVkjoVU_uDK3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/forrestbao/pyeeg.git\n",
      "  Cloning https://github.com/forrestbao/pyeeg.git to /private/var/folders/2w/_k8d4ydx6xq809_sr5s1r7qm0000gn/T/pip-req-build-84vvo9y8\n",
      "  Running command git clone -q https://github.com/forrestbao/pyeeg.git /private/var/folders/2w/_k8d4ydx6xq809_sr5s1r7qm0000gn/T/pip-req-build-84vvo9y8\n",
      "Requirement already satisfied (use --upgrade to upgrade): pyeeg==0.4.4 from git+https://github.com/forrestbao/pyeeg.git in /Users/aaliyah/opt/anaconda3/lib/python3.7/site-packages\n",
      "Requirement already satisfied: numpy>=1.9.2 in /Users/aaliyah/opt/anaconda3/lib/python3.7/site-packages (from pyeeg==0.4.4) (1.17.2)\n",
      "Building wheels for collected packages: pyeeg\n",
      "  Building wheel for pyeeg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyeeg: filename=pyeeg-0.4.4-py2.py3-none-any.whl size=28121 sha256=ebc3292f903a4eb9319eb02e60936f77dc0ace0648c30f1c7cef12ca8ae77fd0\n",
      "  Stored in directory: /private/var/folders/2w/_k8d4ydx6xq809_sr5s1r7qm0000gn/T/pip-ephem-wheel-cache-z39oqi0w/wheels/2d/3f/ad/106d4fc80b61d1ea1fc18e76e7439fd98aa043d83d58eae741\n",
      "Successfully built pyeeg\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/forrestbao/pyeeg.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "XqjBGbE8LBao",
    "outputId": "a752f522-d997-4626-dfd3-6dcfcd4c35f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hai\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"hai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aaliyah/Desktop/biocomp'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd\n",
    "os.chdir('/Users/aaliyah/Desktop/biocomp/')\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SPLfnVBY6LY"
   },
   "outputs": [],
   "source": [
    " import numpy as np\n",
    "\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import pyeeg as pe\n",
    "import pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iq8EcwGxsgw4"
   },
   "outputs": [],
   "source": [
    "channel = [1,2,3,4,6,11,13,17,19,20,21,25,29,31] #14 Channels chosen to fit Emotiv Epoch+\n",
    "band = [4,8,12,16,25,45] #5 bands\n",
    "window_size = 256 #Averaging band power of 2 sec\n",
    "step_size = 16 #Each 0.125 sec update once\n",
    "sample_rate = 70 #Sampling rate of 128 Hz\n",
    "subjectList = ['01','02','03']\n",
    "#List of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PLMSKXbch6TX"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT_Processing (sub, channel, band, window_size, step_size, sample_rate):\n",
    "    '''\n",
    "    arguments:  string subject\n",
    "                list channel indice\n",
    "                list band\n",
    "                int window size for FFT\n",
    "                int step size for FFT\n",
    "                int sample rate for FFT\n",
    "    return:     void\n",
    "    '''\n",
    "    meta = []\n",
    "    with open('DEAP/data_preprocessed_python/s' + sub + '.dat', 'rb') as file:\n",
    "\n",
    "        subject = pickle.load(file, encoding='latin1') #resolve the python 2 data problem by encoding : latin1\n",
    "        for i in range (0,39):\n",
    "            # loop over 0-39 trails\n",
    "            data = subject[\"data\"][i]\n",
    "            labels = subject[\"labels\"][i]\n",
    "            start = 0;\n",
    "\n",
    "            while start + window_size < data.shape[1]:\n",
    "                meta_array = []\n",
    "                meta_data = [] #meta vector for analysis\n",
    "                for j in channel:\n",
    "                    X = data[j][start : start + window_size] #Slice raw data over 2 sec, at interval of 0.125 sec\n",
    "                    Y = pe.bin_power(X, band, sample_rate) #FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\n",
    "                    meta_data = meta_data + list(Y[0])\n",
    "\n",
    "                meta_array.append(np.array(meta_data))\n",
    "                meta_array.append(labels)\n",
    "\n",
    "                meta.append(np.array(meta_array))    \n",
    "                start = start + step_size\n",
    "                \n",
    "        meta = np.array(meta)\n",
    "        print('out/s' + sub)\n",
    "        np.save('out/s' + sub, meta, allow_pickle=True, fix_imports=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzAJVGQBt-5v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/s01\n",
      "out/s02\n",
      "out/s03\n"
     ]
    }
   ],
   "source": [
    "for subjects in subjectList:\n",
    "    FFT_Processing (subjects, channel, band, window_size, step_size, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZGXiP2t2DFC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset: (49959, 70) (49959, 4)\n",
      "testing dataset: (7137, 70) (7137, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nnp.save(\\'out/data_validation\\', np.array(data_validation), allow_pickle=True, fix_imports=True)\\nnp.save(\\'out/label_validation\\', np.array(label_validation), allow_pickle=True, fix_imports=True)\\nprint(\"validation dataset:\", np.array(data_validation).shape, np.array(label_validation).shape)\\n\\n'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = []\n",
    "label_training = []\n",
    "data_testing = []\n",
    "label_testing = []\n",
    "data_validation = []\n",
    "label_validation = []\n",
    "\n",
    "for subjects in subjectList:\n",
    "  \n",
    "\n",
    "    with open('out/s' + subjects + '.npy', 'rb') as file:\n",
    "        sub = np.load(file,allow_pickle=True)\n",
    "        for i in range (0,sub.shape[0]):\n",
    "            if i % 8 == 0 or i % 8== 0:\n",
    "                data_testing.append(sub[i][0])\n",
    "                label_testing.append(sub[i][1])\n",
    "           \n",
    "            else:\n",
    "                data_training.append(sub[i][0])\n",
    "                label_training.append(sub[i][1])\n",
    "\n",
    "np.save('out/data_training', np.array(data_training), allow_pickle=True, fix_imports=True)\n",
    "np.save('out/label_training', np.array(label_training), allow_pickle=True, fix_imports=True)\n",
    "print(\"training dataset:\", np.array(data_training).shape, np.array(label_training).shape)\n",
    "\n",
    "\n",
    "np.save('out/data_testing', np.array(data_testing), allow_pickle=True, fix_imports=True)\n",
    "np.save('out/label_testing', np.array(label_testing), allow_pickle=True, fix_imports=True)\n",
    "print(\"testing dataset:\", np.array(data_testing).shape, np.array(label_testing).shape)\n",
    "\"\"\"\n",
    "np.save('out/data_validation', np.array(data_validation), allow_pickle=True, fix_imports=True)\n",
    "np.save('out/label_validation', np.array(label_validation), allow_pickle=True, fix_imports=True)\n",
    "print(\"validation dataset:\", np.array(data_validation).shape, np.array(label_validation).shape)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFcayQrJ-h0I"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "for subjects in subjectList:\n",
    "  \n",
    "\n",
    "    with open('out/s' + subjects + '.npy', 'rb') as file:\n",
    "        sub = np.load(file,allow_pickle=True)\n",
    "        for i in range (0,sub.shape[0]):\n",
    "            data.append(sub[i][0])\n",
    "            label.append(sub[i][1])\n",
    "np.save('data', np.array(data), allow_pickle=True, fix_imports=True)\n",
    "np.save('label', np.array(label), allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xBM9U5Kht73H"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=data)\n",
    "df.to_csv(\"data.csv\",index=False)\n",
    "\n",
    "df1=pd.DataFrame(data=label)\n",
    "df1.to_csv(\"label.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T3nEbmeVBikG"
   },
   "outputs": [],
   "source": [
    "\n",
    "data1=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "oqaQzAAqBtud",
    "outputId": "33850005-bbc5-4dad-e83e-664c869edb0a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1467.141307</td>\n",
       "      <td>957.354712</td>\n",
       "      <td>975.500368</td>\n",
       "      <td>886.561347</td>\n",
       "      <td>257.611040</td>\n",
       "      <td>1729.379210</td>\n",
       "      <td>1079.293596</td>\n",
       "      <td>1017.848244</td>\n",
       "      <td>950.011987</td>\n",
       "      <td>277.194922</td>\n",
       "      <td>...</td>\n",
       "      <td>1616.579471</td>\n",
       "      <td>1015.132346</td>\n",
       "      <td>769.122057</td>\n",
       "      <td>991.446909</td>\n",
       "      <td>286.112522</td>\n",
       "      <td>1897.870710</td>\n",
       "      <td>1178.996354</td>\n",
       "      <td>740.014784</td>\n",
       "      <td>722.807957</td>\n",
       "      <td>218.773480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1402.080988</td>\n",
       "      <td>872.471171</td>\n",
       "      <td>1069.522141</td>\n",
       "      <td>1008.312775</td>\n",
       "      <td>741.738698</td>\n",
       "      <td>1642.212773</td>\n",
       "      <td>959.802426</td>\n",
       "      <td>1016.890625</td>\n",
       "      <td>1016.753121</td>\n",
       "      <td>486.161277</td>\n",
       "      <td>...</td>\n",
       "      <td>1639.170401</td>\n",
       "      <td>924.285483</td>\n",
       "      <td>828.084355</td>\n",
       "      <td>971.772255</td>\n",
       "      <td>189.171448</td>\n",
       "      <td>1902.103188</td>\n",
       "      <td>1122.875330</td>\n",
       "      <td>761.432035</td>\n",
       "      <td>768.601395</td>\n",
       "      <td>359.695638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1569.859186</td>\n",
       "      <td>895.845443</td>\n",
       "      <td>1035.124465</td>\n",
       "      <td>918.612673</td>\n",
       "      <td>113.293654</td>\n",
       "      <td>1678.108287</td>\n",
       "      <td>964.516236</td>\n",
       "      <td>989.247998</td>\n",
       "      <td>968.499790</td>\n",
       "      <td>138.022717</td>\n",
       "      <td>...</td>\n",
       "      <td>1546.708333</td>\n",
       "      <td>986.628413</td>\n",
       "      <td>876.599937</td>\n",
       "      <td>997.347209</td>\n",
       "      <td>244.353918</td>\n",
       "      <td>2057.569881</td>\n",
       "      <td>1161.216557</td>\n",
       "      <td>736.055635</td>\n",
       "      <td>768.684543</td>\n",
       "      <td>240.153545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1497.247865</td>\n",
       "      <td>851.437981</td>\n",
       "      <td>959.506731</td>\n",
       "      <td>882.725062</td>\n",
       "      <td>260.333692</td>\n",
       "      <td>1537.752623</td>\n",
       "      <td>911.636878</td>\n",
       "      <td>936.074910</td>\n",
       "      <td>956.197358</td>\n",
       "      <td>383.036705</td>\n",
       "      <td>...</td>\n",
       "      <td>1452.084801</td>\n",
       "      <td>914.005947</td>\n",
       "      <td>814.784673</td>\n",
       "      <td>1033.127883</td>\n",
       "      <td>229.448013</td>\n",
       "      <td>1989.591808</td>\n",
       "      <td>1069.121464</td>\n",
       "      <td>686.572034</td>\n",
       "      <td>697.596546</td>\n",
       "      <td>50.708541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1314.476209</td>\n",
       "      <td>919.669964</td>\n",
       "      <td>983.308354</td>\n",
       "      <td>873.276553</td>\n",
       "      <td>352.814075</td>\n",
       "      <td>1351.133996</td>\n",
       "      <td>1007.996757</td>\n",
       "      <td>1000.436238</td>\n",
       "      <td>982.752578</td>\n",
       "      <td>241.910344</td>\n",
       "      <td>...</td>\n",
       "      <td>1433.935229</td>\n",
       "      <td>901.104793</td>\n",
       "      <td>794.645651</td>\n",
       "      <td>1000.369776</td>\n",
       "      <td>199.378771</td>\n",
       "      <td>1739.514883</td>\n",
       "      <td>1011.118559</td>\n",
       "      <td>824.067509</td>\n",
       "      <td>737.803041</td>\n",
       "      <td>496.043021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57091</td>\n",
       "      <td>2941.466671</td>\n",
       "      <td>1667.990021</td>\n",
       "      <td>803.598803</td>\n",
       "      <td>1727.582956</td>\n",
       "      <td>223.909796</td>\n",
       "      <td>1904.887696</td>\n",
       "      <td>1012.261170</td>\n",
       "      <td>516.610274</td>\n",
       "      <td>882.058539</td>\n",
       "      <td>161.676784</td>\n",
       "      <td>...</td>\n",
       "      <td>2627.995444</td>\n",
       "      <td>1496.161376</td>\n",
       "      <td>917.761482</td>\n",
       "      <td>1594.510611</td>\n",
       "      <td>326.740728</td>\n",
       "      <td>2422.375347</td>\n",
       "      <td>1534.229437</td>\n",
       "      <td>898.993497</td>\n",
       "      <td>1709.510794</td>\n",
       "      <td>644.181206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57092</td>\n",
       "      <td>3049.738693</td>\n",
       "      <td>1498.095234</td>\n",
       "      <td>709.837644</td>\n",
       "      <td>1641.664859</td>\n",
       "      <td>126.113945</td>\n",
       "      <td>1926.276835</td>\n",
       "      <td>977.730550</td>\n",
       "      <td>478.385776</td>\n",
       "      <td>835.131073</td>\n",
       "      <td>243.453441</td>\n",
       "      <td>...</td>\n",
       "      <td>2697.377552</td>\n",
       "      <td>1423.471864</td>\n",
       "      <td>994.804976</td>\n",
       "      <td>1580.707942</td>\n",
       "      <td>692.703520</td>\n",
       "      <td>2381.595408</td>\n",
       "      <td>1343.168243</td>\n",
       "      <td>1004.720599</td>\n",
       "      <td>1693.348616</td>\n",
       "      <td>225.530345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57093</td>\n",
       "      <td>2964.787119</td>\n",
       "      <td>1472.638330</td>\n",
       "      <td>636.652963</td>\n",
       "      <td>1655.984762</td>\n",
       "      <td>617.598199</td>\n",
       "      <td>1899.897030</td>\n",
       "      <td>978.312992</td>\n",
       "      <td>485.249539</td>\n",
       "      <td>796.081759</td>\n",
       "      <td>65.974175</td>\n",
       "      <td>...</td>\n",
       "      <td>2678.347948</td>\n",
       "      <td>1383.908050</td>\n",
       "      <td>950.089451</td>\n",
       "      <td>1522.653417</td>\n",
       "      <td>189.358511</td>\n",
       "      <td>2321.112019</td>\n",
       "      <td>1227.066058</td>\n",
       "      <td>909.301931</td>\n",
       "      <td>1690.580232</td>\n",
       "      <td>312.744441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57094</td>\n",
       "      <td>2970.340973</td>\n",
       "      <td>1545.754969</td>\n",
       "      <td>630.235332</td>\n",
       "      <td>1581.842738</td>\n",
       "      <td>328.654513</td>\n",
       "      <td>1850.154481</td>\n",
       "      <td>1026.533202</td>\n",
       "      <td>556.135042</td>\n",
       "      <td>826.079311</td>\n",
       "      <td>140.041788</td>\n",
       "      <td>...</td>\n",
       "      <td>2648.255510</td>\n",
       "      <td>1455.751825</td>\n",
       "      <td>917.489586</td>\n",
       "      <td>1486.280766</td>\n",
       "      <td>191.773088</td>\n",
       "      <td>2354.550619</td>\n",
       "      <td>1168.893927</td>\n",
       "      <td>971.752502</td>\n",
       "      <td>1694.133270</td>\n",
       "      <td>253.219807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57095</td>\n",
       "      <td>2868.539146</td>\n",
       "      <td>1433.048874</td>\n",
       "      <td>630.472243</td>\n",
       "      <td>1443.779869</td>\n",
       "      <td>83.912603</td>\n",
       "      <td>1779.971062</td>\n",
       "      <td>1036.209900</td>\n",
       "      <td>553.687620</td>\n",
       "      <td>838.453628</td>\n",
       "      <td>114.017750</td>\n",
       "      <td>...</td>\n",
       "      <td>2492.285071</td>\n",
       "      <td>1279.431597</td>\n",
       "      <td>872.320766</td>\n",
       "      <td>1428.854053</td>\n",
       "      <td>232.031419</td>\n",
       "      <td>2264.869749</td>\n",
       "      <td>1192.679350</td>\n",
       "      <td>943.719858</td>\n",
       "      <td>1623.675020</td>\n",
       "      <td>266.491813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57096 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3           4  \\\n",
       "0      1467.141307   957.354712   975.500368   886.561347  257.611040   \n",
       "1      1402.080988   872.471171  1069.522141  1008.312775  741.738698   \n",
       "2      1569.859186   895.845443  1035.124465   918.612673  113.293654   \n",
       "3      1497.247865   851.437981   959.506731   882.725062  260.333692   \n",
       "4      1314.476209   919.669964   983.308354   873.276553  352.814075   \n",
       "...            ...          ...          ...          ...         ...   \n",
       "57091  2941.466671  1667.990021   803.598803  1727.582956  223.909796   \n",
       "57092  3049.738693  1498.095234   709.837644  1641.664859  126.113945   \n",
       "57093  2964.787119  1472.638330   636.652963  1655.984762  617.598199   \n",
       "57094  2970.340973  1545.754969   630.235332  1581.842738  328.654513   \n",
       "57095  2868.539146  1433.048874   630.472243  1443.779869   83.912603   \n",
       "\n",
       "                 5            6            7            8           9  ...  \\\n",
       "0      1729.379210  1079.293596  1017.848244   950.011987  277.194922  ...   \n",
       "1      1642.212773   959.802426  1016.890625  1016.753121  486.161277  ...   \n",
       "2      1678.108287   964.516236   989.247998   968.499790  138.022717  ...   \n",
       "3      1537.752623   911.636878   936.074910   956.197358  383.036705  ...   \n",
       "4      1351.133996  1007.996757  1000.436238   982.752578  241.910344  ...   \n",
       "...            ...          ...          ...          ...         ...  ...   \n",
       "57091  1904.887696  1012.261170   516.610274   882.058539  161.676784  ...   \n",
       "57092  1926.276835   977.730550   478.385776   835.131073  243.453441  ...   \n",
       "57093  1899.897030   978.312992   485.249539   796.081759   65.974175  ...   \n",
       "57094  1850.154481  1026.533202   556.135042   826.079311  140.041788  ...   \n",
       "57095  1779.971062  1036.209900   553.687620   838.453628  114.017750  ...   \n",
       "\n",
       "                60           61          62           63          64  \\\n",
       "0      1616.579471  1015.132346  769.122057   991.446909  286.112522   \n",
       "1      1639.170401   924.285483  828.084355   971.772255  189.171448   \n",
       "2      1546.708333   986.628413  876.599937   997.347209  244.353918   \n",
       "3      1452.084801   914.005947  814.784673  1033.127883  229.448013   \n",
       "4      1433.935229   901.104793  794.645651  1000.369776  199.378771   \n",
       "...            ...          ...         ...          ...         ...   \n",
       "57091  2627.995444  1496.161376  917.761482  1594.510611  326.740728   \n",
       "57092  2697.377552  1423.471864  994.804976  1580.707942  692.703520   \n",
       "57093  2678.347948  1383.908050  950.089451  1522.653417  189.358511   \n",
       "57094  2648.255510  1455.751825  917.489586  1486.280766  191.773088   \n",
       "57095  2492.285071  1279.431597  872.320766  1428.854053  232.031419   \n",
       "\n",
       "                65           66           67           68          69  \n",
       "0      1897.870710  1178.996354   740.014784   722.807957  218.773480  \n",
       "1      1902.103188  1122.875330   761.432035   768.601395  359.695638  \n",
       "2      2057.569881  1161.216557   736.055635   768.684543  240.153545  \n",
       "3      1989.591808  1069.121464   686.572034   697.596546   50.708541  \n",
       "4      1739.514883  1011.118559   824.067509   737.803041  496.043021  \n",
       "...            ...          ...          ...          ...         ...  \n",
       "57091  2422.375347  1534.229437   898.993497  1709.510794  644.181206  \n",
       "57092  2381.595408  1343.168243  1004.720599  1693.348616  225.530345  \n",
       "57093  2321.112019  1227.066058   909.301931  1690.580232  312.744441  \n",
       "57094  2354.550619  1168.893927   971.752502  1694.133270  253.219807  \n",
       "57095  2264.869749  1192.679350   943.719858  1623.675020  266.491813  \n",
       "\n",
       "[57096 rows x 70 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "6tjKhClBBvnB",
    "outputId": "adb2fd23-9404-43f3-c0b9-36e96ee1720f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.71</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.71</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.71</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.71</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.71</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57091</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6.21</td>\n",
       "      <td>5.68</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57092</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6.21</td>\n",
       "      <td>5.68</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57093</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6.21</td>\n",
       "      <td>5.68</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57094</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6.21</td>\n",
       "      <td>5.68</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57095</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6.21</td>\n",
       "      <td>5.68</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57096 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3\n",
       "0      7.71  7.60  6.90  7.83\n",
       "1      7.71  7.60  6.90  7.83\n",
       "2      7.71  7.60  6.90  7.83\n",
       "3      7.71  7.60  6.90  7.83\n",
       "4      7.71  7.60  6.90  7.83\n",
       "...     ...   ...   ...   ...\n",
       "57091  4.33  6.21  5.68  4.62\n",
       "57092  4.33  6.21  5.68  4.62\n",
       "57093  4.33  6.21  5.68  4.62\n",
       "57094  4.33  6.21  5.68  4.62\n",
       "57095  4.33  6.21  5.68  4.62\n",
       "\n",
       "[57096 rows x 4 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label1=pd.read_csv(\"label.csv\")\n",
    "label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vHNFxKNCzVA"
   },
   "outputs": [],
   "source": [
    "x=data1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "colab_type": "code",
    "id": "KkOVzVQmDPw8",
    "outputId": "0a73601f-5438-4df1-eb63-c6d084094455"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label1.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t4K0sRcyD7v-"
   },
   "outputs": [],
   "source": [
    "y_val=label1.loc[:,'0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "JIvAMkCWCX93",
    "outputId": "5cbcbc6b-0e6d-40b0-d403-e891bc0f1a5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.71, 8.1 , 8.58, 4.94, 6.96, 8.27, 7.44, 7.32, 4.04, 1.99, 2.99,\n",
       "       2.71, 1.95, 4.18, 3.17, 6.81, 2.46, 7.23, 7.17, 8.26, 9.  , 7.09,\n",
       "       8.15, 7.04, 8.86, 7.28, 7.35, 3.88, 1.36, 2.08, 3.03, 2.28, 3.81,\n",
       "       2.06, 2.9 , 2.31, 3.33, 3.24, 8.01, 6.05, 5.04, 5.  , 4.96, 4.99,\n",
       "       7.08, 8.94, 6.  , 8.97, 1.  , 4.06, 2.01, 4.87, 5.33, 7.21, 7.55,\n",
       "       4.69, 6.92, 6.79, 5.45, 7.14, 7.33, 4.45, 7.94, 6.36, 7.91, 7.29,\n",
       "       7.36, 7.15, 4.56, 7.1 , 8.14, 6.26, 3.65, 3.31, 3.45, 4.67, 6.72,\n",
       "       5.59, 4.47, 3.87, 4.44, 5.17, 4.05, 4.72, 3.18, 5.01, 4.92, 4.53,\n",
       "       4.33])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "c9tQ8UKNfdtI",
    "outputId": "443e457d-ceec-43ae-cb4b-0ba11e055096"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        7.71\n",
       "1        7.71\n",
       "2        7.71\n",
       "3        7.71\n",
       "4        7.71\n",
       "         ... \n",
       "57091    4.33\n",
       "57092    4.33\n",
       "57093    4.33\n",
       "57094    4.33\n",
       "57095    4.33\n",
       "Name: 0, Length: 57096, dtype: float64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "u6OfYsu5oina",
    "outputId": "ee463354-0c37-405c-9494-ed461619e91a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.71, 7.71, 7.71, ..., 4.33, 4.33, 4.33])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "xGLKl-9Zfjaf",
    "outputId": "4fa0b166-ccac-41bd-9582-399e24934e52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.56079892, -0.6150587 , -0.55497708, ..., -0.41330096,\n",
       "        -1.32299145, -0.40788506],\n",
       "       [-0.56646156, -0.64999505, -0.51476463, ..., -0.31285867,\n",
       "        -1.23765226,  0.07824073],\n",
       "       [-0.55185869, -0.64037467, -0.52947627, ..., -0.43186851,\n",
       "        -1.23749731, -0.33413228],\n",
       "       ...,\n",
       "       [-0.43044874, -0.40297836, -0.69989972, ...,  0.38061925,\n",
       "         0.48051812, -0.08372236],\n",
       "       [-0.42996535, -0.37288503, -0.70264449, ...,  0.67349896,\n",
       "         0.48713945, -0.28905884],\n",
       "       [-0.43882585, -0.41927259, -0.70254317, ...,  0.5420319 ,\n",
       "         0.3558357 , -0.24327566]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "x = scaler.transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y_val)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "id": "DQui7-n9Usd3",
    "outputId": "6c250ee0-7487-4f64-9f0c-ccbe0a666c85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.56079892, -0.6150587 , -0.55497708, ..., -0.41330096,\n",
       "        -1.32299145, -0.40788506],\n",
       "       [-0.56646156, -0.64999505, -0.51476463, ..., -0.31285867,\n",
       "        -1.23765226,  0.07824073],\n",
       "       [-0.55185869, -0.64037467, -0.52947627, ..., -0.43186851,\n",
       "        -1.23749731, -0.33413228],\n",
       "       ...,\n",
       "       [-0.43044874, -0.40297836, -0.69989972, ...,  0.38061925,\n",
       "         0.48051812, -0.08372236],\n",
       "       [-0.42996535, -0.37288503, -0.70264449, ...,  0.67349896,\n",
       "         0.48713945, -0.28905884],\n",
       "       [-0.43882585, -0.41927259, -0.70254317, ...,  0.5420319 ,\n",
       "         0.3558357 , -0.24327566]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zru43-IYfvMO"
   },
   "outputs": [],
   "source": [
    "x = np.reshape(x, (x.shape[0],1,x.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "PlVSh-hs3G9M",
    "outputId": "04301f4e-4c56-493c-ec13-0dfa6e7ff0a8",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_ar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-6d97af65ce2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_ar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_ar' is not defined"
     ]
    }
   ],
   "source": [
    "y_ar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Sh3ai8VD1m1a",
    "outputId": "11c9bcfa-c779-4152-95a9-80410d42d98e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57096, 10)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "1TQMW0F7nYL-",
    "outputId": "4fb69115-c565-4d5a-d270-852c89adfe02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EaKwv9nFgEX0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "FRJ5Fu1RmCdj",
    "outputId": "025bf5d0-37e0-4046-e5e5-d4cac40a3754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45676, 1, 70)\n",
      "(45676, 10)\n",
      "(11420, 1, 70)\n",
      "(11420, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "evd-F_sl3wPL",
    "outputId": "1e81b0c5-6407-483c-be5a-71e324891013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 512)         1193984   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 256)         787456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, None, 128)         197120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, None, 64)          49408     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,244,682\n",
      "Trainable params: 2,242,698\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM,BatchNormalization,Activation\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, batch_input_shape = (None, None, x.shape[2]),return_sequences=True))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(256,activation=\"relu\",return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(LSTM(128,activation=\"relu\",return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(64,activation=\"relu\",return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(LSTM(32,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "rmsprop =keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08)\n",
    "model.compile(loss='mean_squared_error',\n",
    "                  optimizer=rmsprop,\n",
    "                  metrics=['accuracy'])\n",
    "#adam = keras.optimizers.Adam(lr=0.5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6aNe2-s1gRTb",
    "outputId": "82dfb09f-03d9-4059-c994-7e1edafe230d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45676 samples, validate on 11420 samples\n",
      "Epoch 1/10\n",
      "45676/45676 [==============================] - 35s 768us/step - loss: 0.2419 - accuracy: 0.1626 - val_loss: 0.2033 - val_accuracy: 0.1788\n",
      "Epoch 2/10\n",
      "45676/45676 [==============================] - 36s 782us/step - loss: 0.2101 - accuracy: 0.1841 - val_loss: 0.1852 - val_accuracy: 0.2137\n",
      "Epoch 3/10\n",
      "45676/45676 [==============================] - 37s 805us/step - loss: 0.1779 - accuracy: 0.1987 - val_loss: 0.1550 - val_accuracy: 0.2124\n",
      "Epoch 4/10\n",
      "45676/45676 [==============================] - 37s 804us/step - loss: 0.1479 - accuracy: 0.2111 - val_loss: 0.1283 - val_accuracy: 0.2431\n",
      "Epoch 5/10\n",
      "45676/45676 [==============================] - 37s 821us/step - loss: 0.1237 - accuracy: 0.2277 - val_loss: 0.1108 - val_accuracy: 0.2533\n",
      "Epoch 6/10\n",
      "45676/45676 [==============================] - 36s 780us/step - loss: 0.1069 - accuracy: 0.2493 - val_loss: 0.0974 - val_accuracy: 0.2888\n",
      "Epoch 7/10\n",
      "45676/45676 [==============================] - 35s 774us/step - loss: 0.0985 - accuracy: 0.2777 - val_loss: 0.0902 - val_accuracy: 0.3405\n",
      "Epoch 8/10\n",
      "45676/45676 [==============================] - 35s 768us/step - loss: 0.0942 - accuracy: 0.3058 - val_loss: 0.0866 - val_accuracy: 0.3435\n",
      "Epoch 9/10\n",
      "45676/45676 [==============================] - 35s 763us/step - loss: 0.0924 - accuracy: 0.3194 - val_loss: 0.0875 - val_accuracy: 0.3458\n",
      "Epoch 10/10\n",
      "45676/45676 [==============================] - 35s 769us/step - loss: 0.0903 - accuracy: 0.3293 - val_loss: 0.0850 - val_accuracy: 0.3553\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 10, batch_size=150,validation_data= (x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "eNF8mZelgcis",
    "outputId": "0244a7e5-ed7f-4b79-cb32-e92657f0c720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, None, 100)         68400     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 99,110\n",
      "Trainable params: 99,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, batch_input_shape = (None, None, x.shape[2]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "rmsprop =keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08)\n",
    "model.compile(loss='mean_squared_error',\n",
    "                  optimizer=rmsprop,\n",
    "                  metrics=['accuracy'])\n",
    "#adam = keras.optimizers.Adam(lr=0.5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13UOXLiKUfBK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KRmWs2V1S4oL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOeAesWjvyTH30TLuaD8D7b",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1oKh3_PBZwmCW5KC0LaLWskFdjnTrXGC4",
   "name": "Copy of erakure.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
